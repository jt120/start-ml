{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "import torch as t\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "import tqdm\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "class Config(object):\n",
    "    data_path = 'data/'  # 诗歌的文本文件存放路径\n",
    "    pickle_path = 'D:/project/ml/test/rnn/input/tang.npz'  # 预处理好的二进制文件\n",
    "    author = None  # 只学习某位作者的诗歌\n",
    "    constrain = None  # 长度限制\n",
    "    category = 'poet.tang'  # 类别，唐诗还是宋诗歌(poet.song)\n",
    "    lr = 1e-3\n",
    "    weight_decay = 1e-4\n",
    "    use_gpu = False\n",
    "    epoch = 1\n",
    "    batch_size = 128\n",
    "    maxlen = 125  # 超过这个长度的之后字被丢弃，小于这个长度的在前面补空格\n",
    "    plot_every = 20  # 每20个batch 可视化一次\n",
    "    # use_env = True # 是否使用visodm\n",
    "    env = 'poetry'  # visdom env\n",
    "    max_gen_len = 200  # 生成诗歌最长长度\n",
    "    debug_file = '/tmp/debugp'\n",
    "    model_path = 'D:/project/ml/data/tang_199.pth'  # 预训练模型路径\n",
    "    prefix_words = '细雨鱼儿出，微风燕子斜。'  # 不是诗歌的组成部分，用来控制生成诗歌的意境\n",
    "    start_words = '闲云潭影日悠悠'  # 诗歌开始\n",
    "    acrostic = False  # 是否是藏头诗\n",
    "    model_prefix = 'checkpoints/tang'  # 模型保存路径\n",
    "\n",
    "opt = Config()\n",
    "\n",
    "class PoetryModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim):\n",
    "        super(PoetryModel, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, self.hidden_dim, num_layers=2)\n",
    "        self.linear1 = nn.Linear(self.hidden_dim, vocab_size)\n",
    "\n",
    "    def forward(self, input, hidden=None):\n",
    "        seq_len, batch_size = input.size()\n",
    "        if hidden is None:\n",
    "            #  h_0 = 0.01*torch.Tensor(2, batch_size, self.hidden_dim).normal_().cuda()\n",
    "            #  c_0 = 0.01*torch.Tensor(2, batch_size, self.hidden_dim).normal_().cuda()\n",
    "            h_0 = input.data.new(2, batch_size, self.hidden_dim).fill_(0).float()\n",
    "            c_0 = input.data.new(2, batch_size, self.hidden_dim).fill_(0).float()\n",
    "        else:\n",
    "            h_0, c_0 = hidden\n",
    "        # size: (seq_len,batch_size,embeding_dim)\n",
    "        embeds = self.embeddings(input)\n",
    "        # output size: (seq_len,batch_size,hidden_dim)\n",
    "        output, hidden = self.lstm(embeds, (h_0, c_0))\n",
    "\n",
    "        # size: (seq_len*batch_size,vocab_size)\n",
    "        output = self.linear1(output.view(seq_len * batch_size, -1))\n",
    "        return output, hidden\n",
    "    \n",
    "def generate(model, start_words, ix2word, word2ix, prefix_words=None):\n",
    "    \"\"\"\n",
    "    给定几个词，根据这几个词接着生成一首完整的诗歌\n",
    "    start_words：u'春江潮水连海平'\n",
    "    比如start_words 为 春江潮水连海平，可以生成：\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    results = list(start_words)\n",
    "    start_word_len = len(start_words)\n",
    "    # 手动设置第一个词为<START>\n",
    "    input = t.Tensor([word2ix['<START>']]).view(1, 1).long()\n",
    "    if opt.use_gpu: input = input.cuda()\n",
    "    hidden = None\n",
    "\n",
    "    if prefix_words:\n",
    "        for word in prefix_words:\n",
    "            output, hidden = model(input, hidden)\n",
    "            input = input.data.new([word2ix[word]]).view(1, 1)\n",
    "\n",
    "    for i in range(opt.max_gen_len):\n",
    "        output, hidden = model(input, hidden)\n",
    "\n",
    "        if i < start_word_len:\n",
    "            w = results[i]\n",
    "            input = input.data.new([word2ix[w]]).view(1, 1)\n",
    "        else:\n",
    "            top_index = output.data[0].topk(1)[1][0].item()\n",
    "            w = ix2word[top_index]\n",
    "            results.append(w)\n",
    "            input = input.data.new([top_index]).view(1, 1)\n",
    "        if w == '<EOP>':\n",
    "            del results[-1]\n",
    "            break\n",
    "    return results\n",
    "\n",
    "\n",
    "def gen_acrostic(model, start_words, ix2word, word2ix, prefix_words=None):\n",
    "    \"\"\"\n",
    "    生成藏头诗\n",
    "    start_words : u'深度学习'\n",
    "    生成：\n",
    "    深木通中岳，青苔半日脂。\n",
    "    度山分地险，逆浪到南巴。\n",
    "    学道兵犹毒，当时燕不移。\n",
    "    习根通古岸，开镜出清羸。\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    start_word_len = len(start_words)\n",
    "    input = (t.Tensor([word2ix['<START>']]).view(1, 1).long())\n",
    "    if opt.use_gpu: input = input.cuda()\n",
    "    hidden = None\n",
    "\n",
    "    index = 0  # 用来指示已经生成了多少句藏头诗\n",
    "    # 上一个词\n",
    "    pre_word = '<START>'\n",
    "\n",
    "    if prefix_words:\n",
    "        for word in prefix_words:\n",
    "            output, hidden = model(input, hidden)\n",
    "            input = (input.data.new([word2ix[word]])).view(1, 1)\n",
    "\n",
    "    for i in range(opt.max_gen_len):\n",
    "        output, hidden = model(input, hidden)\n",
    "        top_index = output.data[0].topk(1)[1][0].item()\n",
    "        w = ix2word[top_index]\n",
    "\n",
    "        if (pre_word in {u'。', u'！', '<START>'}):\n",
    "            # 如果遇到句号，藏头的词送进去生成\n",
    "\n",
    "            if index == start_word_len:\n",
    "                # 如果生成的诗歌已经包含全部藏头的词，则结束\n",
    "                break\n",
    "            else:\n",
    "                # 把藏头的词作为输入送入模型\n",
    "                w = start_words[index]\n",
    "                index += 1\n",
    "                input = (input.data.new([word2ix[w]])).view(1, 1)\n",
    "        else:\n",
    "            # 否则的话，把上一次预测是词作为下一个词输入\n",
    "            input = (input.data.new([word2ix[w]])).view(1, 1)\n",
    "        results.append(w)\n",
    "        pre_word = w\n",
    "    return results\n",
    "\n",
    "def gen(**kwargs):\n",
    "    \"\"\"\n",
    "    提供命令行接口，用以生成相应的诗\n",
    "    \"\"\"\n",
    "\n",
    "    for k, v in kwargs.items():\n",
    "        setattr(opt, k, v)\n",
    "    data, word2ix, ix2word = get_data(opt)\n",
    "    model = PoetryModel(len(word2ix), 128, 256);\n",
    "    map_location = lambda s, l: s\n",
    "    state_dict = t.load(opt.model_path, map_location=map_location)\n",
    "    model.load_state_dict(state_dict)\n",
    "\n",
    "    if opt.use_gpu:\n",
    "        model.cuda()\n",
    "\n",
    "    # python2和python3 字符串兼容\n",
    "    if sys.version_info.major == 3:\n",
    "        if opt.start_words.isprintable():\n",
    "            start_words = opt.start_words\n",
    "            prefix_words = opt.prefix_words if opt.prefix_words else None\n",
    "        else:\n",
    "            start_words = opt.start_words.encode('ascii', 'surrogateescape').decode('utf8')\n",
    "            prefix_words = opt.prefix_words.encode('ascii', 'surrogateescape').decode(\n",
    "                'utf8') if opt.prefix_words else None\n",
    "    else:\n",
    "        start_words = opt.start_words.decode('utf8')\n",
    "        prefix_words = opt.prefix_words.decode('utf8') if opt.prefix_words else None\n",
    "\n",
    "    start_words = start_words.replace(',', u'，') \\\n",
    "        .replace('.', u'。') \\\n",
    "        .replace('?', u'？')\n",
    "\n",
    "    gen_poetry = gen_acrostic if opt.acrostic else generate\n",
    "    result = gen_poetry(model, start_words, ix2word, word2ix, prefix_words)\n",
    "    print(''.join(result))\n",
    "\n",
    "def get_data(opt):\n",
    "    \"\"\"\n",
    "    @param opt 配置选项 Config对象\n",
    "    @return word2ix: dict,每个字对应的序号，形如u'月'->100\n",
    "    @return ix2word: dict,每个序号对应的字，形如'100'->u'月'\n",
    "    @return data: numpy数组，每一行是一首诗对应的字的下标\n",
    "    \"\"\"\n",
    "    if os.path.exists(opt.pickle_path):\n",
    "        data = np.load(opt.pickle_path)\n",
    "        data, word2ix, ix2word = data['data'], data['word2ix'].item(), data['ix2word'].item()\n",
    "        return data, word2ix, ix2word\n",
    "\n",
    "    # 如果没有处理好的二进制文件，则处理原始的json文件\n",
    "    data = _parseRawData(opt.author, opt.constrain, opt.data_path, opt.category)\n",
    "    words = {_word for _sentence in data for _word in _sentence}\n",
    "    word2ix = {_word: _ix for _ix, _word in enumerate(words)}\n",
    "    word2ix['<EOP>'] = len(word2ix)  # 终止标识符\n",
    "    word2ix['<START>'] = len(word2ix)  # 起始标识符\n",
    "    word2ix['</s>'] = len(word2ix)  # 空格\n",
    "    ix2word = {_ix: _word for _word, _ix in list(word2ix.items())}\n",
    "\n",
    "    # 为每首诗歌加上起始符和终止符\n",
    "    for i in range(len(data)):\n",
    "        data[i] = [\"<START>\"] + list(data[i]) + [\"<EOP>\"]\n",
    "\n",
    "    # 将每首诗歌保存的内容由‘字’变成‘数’\n",
    "    # 形如[春,江,花,月,夜]变成[1,2,3,4,5]\n",
    "    new_data = [[word2ix[_word] for _word in _sentence]\n",
    "                for _sentence in data]\n",
    "\n",
    "    # 诗歌长度不够opt.maxlen的在前面补空格，超过的，删除末尾的\n",
    "    pad_data = pad_sequences(new_data,\n",
    "                             maxlen=opt.maxlen,\n",
    "                             padding='pre',\n",
    "                             truncating='post',\n",
    "                             value=len(word2ix) - 1)\n",
    "\n",
    "    # 保存成二进制文件\n",
    "    np.savez_compressed(opt.pickle_path,\n",
    "                        data=pad_data,\n",
    "                        word2ix=word2ix,\n",
    "                        ix2word=ix2word)\n",
    "    return pad_data, word2ix, ix2word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, word2ix, ix2word = get_data(opt)\n",
    "data = t.from_numpy(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'</s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s><START>夏景已难度，怀贤思方续。乔树落疎阴，微风散烦燠。伤离枉芳札，忻遂见心曲。蓝上舍已成，田家雨新足。讬邻素多欲，残帙犹见束。日夕上高斋，但望东原绿。<EOP>'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''.join([ix2word[x.item()] for x in data[10]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([57580, 125])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'</s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s><START>紫烟楼阁碧纱亭，上界诗仙独自行。奇险驱回还寂寞，云山经用始鲜明。藕绡纹缕裁来滑，镜水波涛滤得清。昏思愿因秋露洗，幸容堦下礼先生。<EOP>'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = np.random.choice(range(data.shape[0]), size=1)\n",
    "''.join([ix2word[x.item()] for x in data[index.item()]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8293"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word2ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "0it [00:00, ?it/s]\n",
      "\n",
      "\n",
      "\n",
      "1it [00:04,  4.12s/it]\n",
      "\n",
      "\n",
      "\n",
      "2it [00:07,  3.85s/it]\n",
      "\n",
      "\n",
      "\n",
      "3it [00:11,  3.84s/it]\n",
      "\n",
      "\n",
      "\n",
      "4it [00:15,  3.82s/it]\n",
      "\n",
      "\n",
      "\n",
      "5it [00:19,  3.84s/it]\n",
      "\n",
      "\n",
      "\n",
      "6it [00:24,  4.03s/it]\n",
      "\n",
      "\n",
      "\n",
      "7it [00:28,  4.08s/it]\n",
      "\n",
      "\n",
      "\n",
      "8it [00:32,  4.12s/it]\n",
      "\n",
      "\n",
      "\n",
      "9it [00:38,  4.23s/it]\n",
      "\n",
      "\n",
      "\n",
      "10it [00:42,  4.27s/it]\n",
      "\n",
      "\n",
      "\n",
      "11it [00:47,  4.27s/it]\n",
      "\n",
      "\n",
      "\n",
      "12it [00:51,  4.31s/it]\n",
      "\n",
      "\n",
      "\n",
      "13it [00:56,  4.37s/it]\n",
      "\n",
      "\n",
      "\n",
      "14it [01:01,  4.42s/it]\n",
      "\n",
      "\n",
      "\n",
      "15it [01:06,  4.47s/it]\n",
      "\n",
      "\n",
      "\n",
      "16it [01:11,  4.50s/it]\n",
      "\n",
      "\n",
      "\n",
      "17it [01:16,  4.52s/it]\n",
      "\n",
      "\n",
      "\n",
      "18it [01:21,  4.53s/it]\n",
      "\n",
      "\n",
      "\n",
      "19it [01:26,  4.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 3.632603883743286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "20it [01:31,  4.57s/it]\n",
      "\n",
      "\n",
      "\n",
      "21it [01:36,  4.57s/it]\n",
      "\n",
      "\n",
      "\n",
      "22it [01:40,  4.57s/it]\n",
      "\n",
      "\n",
      "\n",
      "23it [01:44,  4.56s/it]\n",
      "\n",
      "\n",
      "\n",
      "24it [01:49,  4.56s/it]\n",
      "\n",
      "\n",
      "\n",
      "25it [01:53,  4.56s/it]\n",
      "\n",
      "\n",
      "\n",
      "26it [01:58,  4.56s/it]\n",
      "\n",
      "\n",
      "\n",
      "27it [02:02,  4.55s/it]\n",
      "\n",
      "\n",
      "\n",
      "28it [02:07,  4.55s/it]\n",
      "\n",
      "\n",
      "\n",
      "29it [02:12,  4.55s/it]\n",
      "\n",
      "\n",
      "\n",
      "30it [02:16,  4.55s/it]\n",
      "\n",
      "\n",
      "\n",
      "31it [02:21,  4.58s/it]\n",
      "\n",
      "\n",
      "\n",
      "32it [02:26,  4.59s/it]\n",
      "\n",
      "\n",
      "\n",
      "33it [02:31,  4.58s/it]\n",
      "\n",
      "\n",
      "\n",
      "34it [02:35,  4.58s/it]\n",
      "\n",
      "\n",
      "\n",
      "35it [02:40,  4.58s/it]\n",
      "\n",
      "\n",
      "\n",
      "36it [02:45,  4.58s/it]\n",
      "\n",
      "\n",
      "\n",
      "37it [02:50,  4.60s/it]\n",
      "\n",
      "\n",
      "\n",
      "38it [02:55,  4.61s/it]\n",
      "\n",
      "\n",
      "\n",
      "39it [03:00,  4.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 3.09531831741333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "40it [03:05,  4.64s/it]\n",
      "\n",
      "\n",
      "\n",
      "41it [03:10,  4.65s/it]\n",
      "\n",
      "\n",
      "\n",
      "42it [03:16,  4.67s/it]\n",
      "\n",
      "\n",
      "\n",
      "43it [03:22,  4.71s/it]\n",
      "\n",
      "\n",
      "\n",
      "44it [03:26,  4.70s/it]\n",
      "\n",
      "\n",
      "\n",
      "45it [03:31,  4.69s/it]\n",
      "\n",
      "\n",
      "\n",
      "46it [03:35,  4.68s/it]\n",
      "\n",
      "\n",
      "\n",
      "47it [03:39,  4.68s/it]\n",
      "\n",
      "\n",
      "\n",
      "48it [03:44,  4.67s/it]\n",
      "\n",
      "\n",
      "\n",
      "49it [03:48,  4.66s/it]\n",
      "\n",
      "\n",
      "\n",
      "50it [03:52,  4.66s/it]\n",
      "\n",
      "\n",
      "\n",
      "51it [03:57,  4.66s/it]\n",
      "\n",
      "\n",
      "\n",
      "52it [04:02,  4.66s/it]\n",
      "\n",
      "\n",
      "\n",
      "53it [04:07,  4.67s/it]\n",
      "\n",
      "\n",
      "\n",
      "54it [04:11,  4.66s/it]\n",
      "\n",
      "\n",
      "\n",
      "55it [04:16,  4.65s/it]\n",
      "\n",
      "\n",
      "\n",
      "56it [04:20,  4.65s/it]\n",
      "\n",
      "\n",
      "\n",
      "57it [04:24,  4.64s/it]\n",
      "\n",
      "\n",
      "\n",
      "58it [04:29,  4.64s/it]\n",
      "\n",
      "\n",
      "\n",
      "59it [04:33,  4.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 2.913165330886841\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "60it [04:37,  4.63s/it]\n",
      "\n",
      "\n",
      "\n",
      "61it [04:42,  4.63s/it]\n",
      "\n",
      "\n",
      "\n",
      "62it [04:46,  4.62s/it]\n",
      "\n",
      "\n",
      "\n",
      "63it [04:51,  4.62s/it]\n",
      "\n",
      "\n",
      "\n",
      "64it [04:55,  4.62s/it]\n",
      "\n",
      "\n",
      "\n",
      "65it [04:59,  4.61s/it]\n",
      "\n",
      "\n",
      "\n",
      "66it [05:04,  4.61s/it]\n",
      "\n",
      "\n",
      "\n",
      "67it [05:08,  4.61s/it]\n",
      "\n",
      "\n",
      "\n",
      "68it [05:13,  4.61s/it]\n",
      "\n",
      "\n",
      "\n",
      "69it [05:18,  4.61s/it]\n",
      "\n",
      "\n",
      "\n",
      "70it [05:23,  4.61s/it]\n",
      "\n",
      "\n",
      "\n",
      "71it [05:27,  4.61s/it]\n",
      "\n",
      "\n",
      "\n",
      "72it [05:32,  4.62s/it]\n",
      "\n",
      "\n",
      "\n",
      "73it [05:36,  4.61s/it]\n",
      "\n",
      "\n",
      "\n",
      "74it [05:41,  4.62s/it]\n",
      "\n",
      "\n",
      "\n",
      "75it [05:46,  4.62s/it]\n",
      "\n",
      "\n",
      "\n",
      "76it [05:50,  4.61s/it]\n",
      "\n",
      "\n",
      "\n",
      "77it [05:54,  4.61s/it]\n",
      "\n",
      "\n",
      "\n",
      "78it [05:59,  4.61s/it]\n",
      "\n",
      "\n",
      "\n",
      "79it [06:03,  4.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 2.8733842372894287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "80it [06:07,  4.60s/it]\n",
      "\n",
      "\n",
      "\n",
      "81it [06:12,  4.60s/it]\n",
      "\n",
      "\n",
      "\n",
      "82it [06:16,  4.60s/it]\n",
      "\n",
      "\n",
      "\n",
      "83it [06:21,  4.60s/it]\n",
      "\n",
      "\n",
      "\n",
      "84it [06:26,  4.60s/it]\n",
      "\n",
      "\n",
      "\n",
      "85it [06:31,  4.61s/it]\n",
      "\n",
      "\n",
      "\n",
      "86it [06:36,  4.61s/it]\n",
      "\n",
      "\n",
      "\n",
      "87it [06:40,  4.61s/it]\n",
      "\n",
      "\n",
      "\n",
      "88it [06:45,  4.61s/it]\n",
      "\n",
      "\n",
      "\n",
      "89it [06:49,  4.61s/it]\n",
      "\n",
      "\n",
      "\n",
      "90it [06:54,  4.60s/it]\n",
      "\n",
      "\n",
      "\n",
      "91it [06:58,  4.60s/it]\n",
      "\n",
      "\n",
      "\n",
      "92it [07:03,  4.60s/it]\n",
      "\n",
      "\n",
      "\n",
      "93it [07:07,  4.60s/it]\n",
      "\n",
      "\n",
      "\n",
      "94it [07:11,  4.59s/it]\n",
      "\n",
      "\n",
      "\n",
      "95it [07:16,  4.59s/it]\n",
      "\n",
      "\n",
      "\n",
      "96it [07:21,  4.60s/it]\n",
      "\n",
      "\n",
      "\n",
      "97it [07:26,  4.60s/it]\n",
      "\n",
      "\n",
      "\n",
      "98it [07:30,  4.60s/it]\n",
      "\n",
      "\n",
      "\n",
      "99it [07:35,  4.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 2.774152994155884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "100it [07:40,  4.60s/it]\n",
      "\n",
      "\n",
      "\n",
      "101it [07:44,  4.60s/it]\n",
      "\n",
      "\n",
      "\n",
      "102it [07:49,  4.60s/it]\n",
      "\n",
      "\n",
      "\n",
      "103it [07:53,  4.60s/it]\n",
      "\n",
      "\n",
      "\n",
      "104it [07:57,  4.59s/it]\n",
      "\n",
      "\n",
      "\n",
      "105it [08:02,  4.59s/it]\n",
      "\n",
      "\n",
      "\n",
      "106it [08:06,  4.59s/it]\n",
      "\n",
      "\n",
      "\n",
      "107it [08:10,  4.59s/it]\n",
      "\n",
      "\n",
      "\n",
      "108it [08:15,  4.59s/it]\n",
      "\n",
      "\n",
      "\n",
      "109it [08:20,  4.59s/it]\n",
      "\n",
      "\n",
      "\n",
      "110it [08:24,  4.59s/it]\n",
      "\n",
      "\n",
      "\n",
      "111it [08:29,  4.59s/it]\n",
      "\n",
      "\n",
      "\n",
      "112it [08:33,  4.59s/it]\n",
      "\n",
      "\n",
      "\n",
      "113it [08:38,  4.59s/it]\n",
      "\n",
      "\n",
      "\n",
      "114it [08:43,  4.59s/it]\n",
      "\n",
      "\n",
      "\n",
      "115it [08:48,  4.59s/it]\n",
      "\n",
      "\n",
      "\n",
      "116it [08:53,  4.60s/it]\n",
      "\n",
      "\n",
      "\n",
      "117it [08:58,  4.60s/it]\n",
      "\n",
      "\n",
      "\n",
      "118it [09:03,  4.61s/it]\n",
      "\n",
      "\n",
      "\n",
      "119it [09:08,  4.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 2.8415277004241943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "120it [09:12,  4.61s/it]\n",
      "\n",
      "\n",
      "\n",
      "121it [09:16,  4.60s/it]\n",
      "\n",
      "\n",
      "\n",
      "122it [09:21,  4.60s/it]\n",
      "\n",
      "\n",
      "\n",
      "123it [09:26,  4.60s/it]\n",
      "\n",
      "\n",
      "\n",
      "124it [09:30,  4.60s/it]\n",
      "\n",
      "\n",
      "\n",
      "125it [09:35,  4.60s/it]\n",
      "\n",
      "\n",
      "\n",
      "126it [09:39,  4.60s/it]\n",
      "\n",
      "\n",
      "\n",
      "127it [09:44,  4.60s/it]\n",
      "\n",
      "\n",
      "\n",
      "128it [09:48,  4.60s/it]\n",
      "\n",
      "\n",
      "\n",
      "129it [09:53,  4.60s/it]\n",
      "\n",
      "\n",
      "\n",
      "130it [09:58,  4.61s/it]\n",
      "\n",
      "\n",
      "\n",
      "131it [10:03,  4.61s/it]\n",
      "\n",
      "\n",
      "\n",
      "132it [10:08,  4.61s/it]\n",
      "\n",
      "\n",
      "\n",
      "133it [10:13,  4.61s/it]\n",
      "\n",
      "\n",
      "\n",
      "134it [10:18,  4.61s/it]\n",
      "\n",
      "\n",
      "\n",
      "135it [10:22,  4.61s/it]\n",
      "\n",
      "\n",
      "\n",
      "136it [10:27,  4.61s/it]\n",
      "\n",
      "\n",
      "\n",
      "137it [10:31,  4.61s/it]\n",
      "\n",
      "\n",
      "\n",
      "138it [10:35,  4.61s/it]\n",
      "\n",
      "\n",
      "\n",
      "139it [10:40,  4.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 2.8828182220458984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "140it [10:44,  4.61s/it]\n",
      "\n",
      "\n",
      "\n",
      "141it [10:49,  4.61s/it]\n",
      "\n",
      "\n",
      "\n",
      "142it [10:53,  4.60s/it]\n",
      "\n",
      "\n",
      "\n",
      "143it [10:58,  4.60s/it]\n",
      "\n",
      "\n",
      "\n",
      "144it [11:02,  4.60s/it]\n",
      "\n",
      "\n",
      "\n",
      "145it [11:06,  4.60s/it]\n",
      "\n",
      "\n",
      "\n",
      "146it [11:11,  4.60s/it]\n",
      "\n",
      "\n",
      "\n",
      "147it [11:15,  4.60s/it]\n",
      "\n",
      "\n",
      "\n",
      "148it [11:20,  4.60s/it]\n",
      "\n",
      "\n",
      "\n",
      "149it [11:24,  4.60s/it]\n",
      "\n",
      "\n",
      "\n",
      "150it [11:29,  4.60s/it]\n",
      "\n",
      "\n",
      "\n",
      "151it [11:34,  4.60s/it]\n",
      "\n",
      "\n",
      "\n",
      "152it [11:38,  4.60s/it]\n",
      "\n",
      "\n",
      "\n",
      "153it [11:43,  4.60s/it]\n",
      "\n",
      "\n",
      "\n",
      "154it [11:47,  4.60s/it]\n",
      "\n",
      "\n",
      "\n",
      "155it [11:52,  4.60s/it]\n",
      "\n",
      "\n",
      "\n",
      "156it [11:56,  4.59s/it]\n",
      "\n",
      "\n",
      "\n",
      "157it [12:01,  4.59s/it]\n",
      "\n",
      "\n",
      "\n",
      "158it [12:05,  4.59s/it]\n",
      "\n",
      "\n",
      "\n",
      "159it [12:10,  4.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 2.982400894165039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "160it [12:15,  4.60s/it]\n",
      "\n",
      "\n",
      "\n",
      "161it [12:19,  4.60s/it]\n",
      "\n",
      "\n",
      "\n",
      "162it [12:26,  4.61s/it]\n",
      "\n",
      "\n",
      "\n",
      "163it [12:31,  4.61s/it]\n",
      "\n",
      "\n",
      "\n",
      "164it [12:35,  4.61s/it]\n",
      "\n",
      "\n",
      "\n",
      "165it [12:40,  4.61s/it]\n",
      "\n",
      "\n",
      "\n",
      "166it [12:44,  4.61s/it]\n",
      "\n",
      "\n",
      "\n",
      "167it [12:49,  4.61s/it]\n",
      "\n",
      "\n",
      "\n",
      "168it [12:54,  4.61s/it]\n",
      "\n",
      "\n",
      "\n",
      "169it [12:58,  4.61s/it]\n",
      "\n",
      "\n",
      "\n",
      "170it [13:02,  4.61s/it]\n",
      "\n",
      "\n",
      "\n",
      "171it [13:07,  4.61s/it]\n",
      "\n",
      "\n",
      "\n",
      "172it [13:12,  4.61s/it]\n",
      "\n",
      "\n",
      "\n",
      "173it [13:17,  4.61s/it]\n",
      "\n",
      "\n",
      "\n",
      "174it [13:21,  4.61s/it]\n",
      "\n",
      "\n",
      "\n",
      "175it [13:26,  4.61s/it]\n",
      "\n",
      "\n",
      "\n",
      "176it [13:30,  4.61s/it]\n",
      "\n",
      "\n",
      "\n",
      "177it [13:35,  4.61s/it]\n",
      "\n",
      "\n",
      "\n",
      "178it [13:39,  4.61s/it]\n",
      "\n",
      "\n",
      "\n",
      "179it [13:44,  4.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 2.8406317234039307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "180it [13:48,  4.60s/it]\n",
      "\n",
      "\n",
      "\n",
      "181it [13:52,  4.60s/it]\n",
      "\n",
      "\n",
      "\n",
      "182it [13:57,  4.60s/it]\n",
      "\n",
      "\n",
      "\n",
      "183it [14:01,  4.60s/it]\n",
      "\n",
      "\n",
      "\n",
      "184it [14:06,  4.60s/it]\n",
      "\n",
      "\n",
      "\n",
      "185it [14:10,  4.60s/it]\n",
      "\n",
      "\n",
      "\n",
      "186it [14:14,  4.60s/it]\n",
      "\n",
      "\n",
      "\n",
      "187it [14:19,  4.59s/it]\n",
      "\n",
      "\n",
      "\n",
      "188it [14:23,  4.59s/it]\n",
      "\n",
      "\n",
      "\n",
      "189it [14:27,  4.59s/it]\n",
      "\n",
      "\n",
      "\n",
      "190it [14:32,  4.59s/it]\n",
      "\n",
      "\n",
      "\n",
      "191it [14:36,  4.59s/it]\n",
      "\n",
      "\n",
      "\n",
      "192it [14:41,  4.59s/it]\n",
      "\n",
      "\n",
      "\n",
      "193it [14:45,  4.59s/it]\n",
      "\n",
      "\n",
      "\n",
      "194it [14:49,  4.59s/it]\n",
      "\n",
      "\n",
      "\n",
      "195it [14:54,  4.59s/it]\n",
      "\n",
      "\n",
      "\n",
      "196it [14:58,  4.58s/it]\n",
      "\n",
      "\n",
      "\n",
      "197it [15:03,  4.58s/it]\n",
      "\n",
      "\n",
      "\n",
      "198it [15:07,  4.58s/it]\n",
      "\n",
      "\n",
      "\n",
      "199it [15:11,  4.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 2.4145264625549316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "200it [15:16,  4.58s/it]\n",
      "\n",
      "\n",
      "\n",
      "201it [15:20,  4.58s/it]\n",
      "\n",
      "\n",
      "\n",
      "202it [15:25,  4.58s/it]\n",
      "\n",
      "\n",
      "\n",
      "203it [15:29,  4.58s/it]\n",
      "\n",
      "\n",
      "\n",
      "204it [15:33,  4.58s/it]\n",
      "\n",
      "\n",
      "\n",
      "205it [15:38,  4.58s/it]\n",
      "\n",
      "\n",
      "\n",
      "206it [15:42,  4.57s/it]\n",
      "\n",
      "\n",
      "\n",
      "207it [15:46,  4.57s/it]\n",
      "\n",
      "\n",
      "\n",
      "208it [15:51,  4.57s/it]\n",
      "\n",
      "\n",
      "\n",
      "209it [15:55,  4.57s/it]\n",
      "\n",
      "\n",
      "\n",
      "210it [15:59,  4.57s/it]\n",
      "\n",
      "\n",
      "\n",
      "211it [16:04,  4.57s/it]\n",
      "\n",
      "\n",
      "\n",
      "212it [16:08,  4.57s/it]\n",
      "\n",
      "\n",
      "\n",
      "213it [16:12,  4.57s/it]\n",
      "\n",
      "\n",
      "\n",
      "214it [16:17,  4.57s/it]\n",
      "\n",
      "\n",
      "\n",
      "215it [16:21,  4.57s/it]\n",
      "\n",
      "\n",
      "\n",
      "216it [16:26,  4.57s/it]\n",
      "\n",
      "\n",
      "\n",
      "217it [16:30,  4.56s/it]\n",
      "\n",
      "\n",
      "\n",
      "218it [16:34,  4.56s/it]\n",
      "\n",
      "\n",
      "\n",
      "219it [16:39,  4.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 2.854132890701294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "220it [16:43,  4.56s/it]\n",
      "\n",
      "\n",
      "\n",
      "221it [16:47,  4.56s/it]\n",
      "\n",
      "\n",
      "\n",
      "222it [16:52,  4.56s/it]\n",
      "\n",
      "\n",
      "\n",
      "223it [16:56,  4.56s/it]\n",
      "\n",
      "\n",
      "\n",
      "224it [17:01,  4.56s/it]\n",
      "\n",
      "\n",
      "\n",
      "225it [17:05,  4.56s/it]\n",
      "\n",
      "\n",
      "\n",
      "226it [17:09,  4.56s/it]\n",
      "\n",
      "\n",
      "\n",
      "227it [17:14,  4.56s/it]\n",
      "\n",
      "\n",
      "\n",
      "228it [17:18,  4.55s/it]\n",
      "\n",
      "\n",
      "\n",
      "229it [17:22,  4.55s/it]\n",
      "\n",
      "\n",
      "\n",
      "230it [17:27,  4.55s/it]\n",
      "\n",
      "\n",
      "\n",
      "231it [17:31,  4.55s/it]\n",
      "\n",
      "\n",
      "\n",
      "232it [17:36,  4.55s/it]\n",
      "\n",
      "\n",
      "\n",
      "233it [17:40,  4.55s/it]\n",
      "\n",
      "\n",
      "\n",
      "234it [17:45,  4.55s/it]\n",
      "\n",
      "\n",
      "\n",
      "235it [17:49,  4.55s/it]\n",
      "\n",
      "\n",
      "\n",
      "236it [17:54,  4.55s/it]\n",
      "\n",
      "\n",
      "\n",
      "237it [17:58,  4.55s/it]\n",
      "\n",
      "\n",
      "\n",
      "238it [18:03,  4.55s/it]\n",
      "\n",
      "\n",
      "\n",
      "239it [18:07,  4.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 2.6666290760040283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "240it [18:12,  4.55s/it]\n",
      "\n",
      "\n",
      "\n",
      "241it [18:16,  4.55s/it]\n",
      "\n",
      "\n",
      "\n",
      "242it [18:21,  4.55s/it]\n",
      "\n",
      "\n",
      "\n",
      "243it [18:26,  4.55s/it]\n",
      "\n",
      "\n",
      "\n",
      "244it [18:31,  4.55s/it]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-58-06557cff080a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[0minput_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m         \u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    476\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 477\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    478\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-54-feb8f022b63b>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, hidden)\u001b[0m\n\u001b[0;32m     54\u001b[0m         \u001b[0membeds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membeddings\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m         \u001b[1;31m# output size: (seq_len,batch_size,hidden_dim)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 56\u001b[1;33m         \u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0membeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mh_0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc_0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m         \u001b[1;31m# size: (seq_len*batch_size,vocab_size)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    476\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 477\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    478\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    190\u001b[0m             \u001b[0mflat_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mflat_weight\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    191\u001b[0m         )\n\u001b[1;32m--> 192\u001b[1;33m         \u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mall_weights\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    193\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_packed\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    194\u001b[0m             \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPackedSequence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_functions\\rnn.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(input, *fargs, **fkwargs)\u001b[0m\n\u001b[0;32m    322\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdecorator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    323\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 324\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mfargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    325\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    326\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_functions\\rnn.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(input, weight, hidden, batch_sizes)\u001b[0m\n\u001b[0;32m    242\u001b[0m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    243\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 244\u001b[1;33m         \u001b[0mnexth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    245\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    246\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mbatch_first\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mvariable_length\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_functions\\rnn.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(input, hidden, weight, batch_sizes)\u001b[0m\n\u001b[0;32m     85\u001b[0m                 \u001b[0ml\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnum_directions\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 87\u001b[1;33m                 \u001b[0mhy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minner\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m                 \u001b[0mnext_hidden\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m                 \u001b[0mall_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_functions\\rnn.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(input, hidden, weight, batch_sizes)\u001b[0m\n\u001b[0;32m    114\u001b[0m         \u001b[0msteps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mreverse\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msteps\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 116\u001b[1;33m             \u001b[0mhidden\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minner\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    117\u001b[0m             \u001b[1;31m# hack to handle LSTM\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m             \u001b[0moutput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mhidden\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_functions\\rnn.py\u001b[0m in \u001b[0;36mLSTMCell\u001b[1;34m(input, hidden, w_ih, w_hh, b_ih, b_hh)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[0mhx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhidden\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m     \u001b[0mgates\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw_ih\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb_ih\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw_hh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb_hh\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m     \u001b[0mingate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mforgetgate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcellgate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutgate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgates\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchunk\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mlinear\u001b[1;34m(input, weight, bias)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1023\u001b[0m         \u001b[1;31m# fused op is marginally faster\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1024\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1025\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1026\u001b[0m     \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dataloader = DataLoader(data,\n",
    "                         batch_size=opt.batch_size,\n",
    "                         shuffle=True,\n",
    "                         num_workers=1)\n",
    "\n",
    "# 模型定义\n",
    "model = PoetryModel(len(word2ix), 128, 256)\n",
    "optimizer = t.optim.Adam(model.parameters(), lr=opt.lr)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "l = []\n",
    "for epoch in range(opt.epoch):\n",
    "    for ii, data_ in tqdm.tqdm(enumerate(dataloader)):\n",
    "\n",
    "        # 训练\n",
    "        data_ = data_.long().transpose(1, 0).contiguous()\n",
    "        optimizer.zero_grad()\n",
    "        input_, target = Variable(data_[:-1, :]), Variable(data_[1:, :])\n",
    "        output, _ = model(input_)\n",
    "        loss = criterion(output, target.view(-1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "        # 可视化\n",
    "        if (1 + ii) % opt.plot_every == 0:\n",
    "\n",
    "            l.append(loss.item())\n",
    "            print('loss', loss.item())\n",
    "            # 诗歌原文\n",
    "#             poetrys = [[ix2word[_word.item()] for _word in data_[:, _iii]]\n",
    "#                        for _iii in range(data_.size(1))][:16]\n",
    "#             txt = '</br>'.join([''.join(poetry) for poetry in poetrys])\n",
    "#             print('origin:', txt)\n",
    "\n",
    "#             gen_poetries = []\n",
    "#             # 分别以这几个字作为诗歌的第一个字，生成8首诗\n",
    "#             for word in list(u'春江花月夜凉如水'):\n",
    "#                 gen_poetry = ''.join(generate(model, word, ix2word, word2ix))\n",
    "#                 gen_poetries.append(gen_poetry)\n",
    "#             txt = '</br>'.join([''.join(poetry) for poetry in gen_poetries])\n",
    "#             print('generate:', txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.6752970218658447"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data_[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([8292, 8292, 8292, 8292, 8292, 8292, 8292, 8292, 8292, 8292, 8292, 8292,\n",
       "        8292, 8292, 8292, 8292, 8292, 8292, 8292, 8292, 8292, 8292, 8292, 8292,\n",
       "        8292, 8292, 8292, 8292, 8292, 8292, 8292, 8292, 8292, 8292, 8292, 8292,\n",
       "        8292, 8292, 8292, 8292, 8292, 8292, 8292, 8292, 8292, 8292, 8292, 8292,\n",
       "        8292, 8292, 8292, 8292, 8292, 8292, 8292, 8292, 8292, 8292, 8292, 8292,\n",
       "        8292, 8292, 8292, 8292, 8292, 8292, 8292, 8292, 8292, 8292, 8292, 8292,\n",
       "        8292, 8292, 8292, 8291, 4038, 2958, 3189, 1175, 4624, 7066, 7630, 3520,\n",
       "        4710, 1161,  745, 7435, 6225, 3929, 4744, 3286, 7310, 7066, 1787, 1360,\n",
       "        8010, 6787, 7914, 7435, 1719, 2808, 6016, 4782, 4414, 7066, 7854, 7377,\n",
       "        6663, 3243, 1540, 7435, 8033, 2884, 4054, 3465, 8150, 7066, 3969, 5135,\n",
       "        5283,   70, 7905, 7435, 8290])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'</s>'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ix2word[8292]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = t.Tensor([1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "poetrys = [[ix2word[_word.item()] for _word in data_[:, _iii]]\n",
    "                       for _iii in range(data_.size(1))][:16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'</s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s><START>谷中春日暖，渐忆掇茶英。欲及清明火，能销醉客酲。松花飘鼎泛，兰气入瓯轻。饮罢闲无事，扪萝溪上行。<EOP></br><START>游人夜到汝阳间，夜色冥濛不解颜。谁家暗起寒山烧，因此明中得见山。山头山下须臾满，历险缘深无暂断。焦声散著羣树鸣，炎气傍林一川暖。是时西北多海风，吹上连天光更雄。浊烟熏月黑，高豔爇云红。初谓炼丹仙灶里，还疑铸劒神谿中。划为飞电来照物，乍作流星并上空。</br><START>少年落魄楚汉间，风尘萧瑟多苦颜。自言管葛竟谁许，长吁莫错还闭关。一朝君王垂拂拭，剖心输丹雪胸臆。忽蒙白日回景光，直上青云生羽翼。幸陪鸞辇出鸿都，身骑飞龙天马驹。王公大人借颜色，金璋紫绶来相趋。当时结交何纷纷，片言道合惟有君。待吾尽节报明主，然后相携</br></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s><START>天子卹疲瘵，坤灵奉其职。年年济世功，贵贱相兼植。因产众草中，所希采者识。一枝当若神，千金亦何直。生草不生药，无以彰土德。生药不生草，无以彰奇特。国忠在臣贤，民患凭药力。灵草犹如此，贤人岂多得。<EOP></br></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s><START>生长在荥阳，少小辞乡曲。迢迢四十载，复向荥阳宿。去时十一二，今年五十六。追思儿戏时，宛然犹在目。旧居失处所，故里无宗族。岂唯变市朝，兼亦迁陵谷。独有溱洧水，无情依旧绿。<EOP></br></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s><START>阻他罗网到柴扉，不奈偷仓雀转肥。赖尔林塘添景趣，剩留山果引教归。<EOP></br></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s><START>卷荷香澹浮烟渚，绿嫩擎新雨。琐窗疎透晓风清，象床珍簟冷光轻，水文平。九疑黛色屏斜掩，枕上眉心歛。不堪相望病将成，钿昏檀粉泪纵横，不胜情。<EOP></br></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s><START>彼美汉东国，川藏明月辉。宁知丧乱后，更有一珠归。<EOP></br><START>善为尔诸身，行为尔性命。祸福必可转，莫悫言前定。见人之得，如己之得。则美无不克，见人之失。如己之失，是亨贞吉。反此之徒，天鬼必诛。福先祸始，好杀灭纪。不得不止，守谦寡慾。善善恶恶，不得不作。无见贵热，谄走蹩躠。无轻贱微，上下相依。古圣著书，矻矻孳孳</br></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s><START>绰约小天仙，生来十六年。姑山半峰雪，瑶水一枝莲。晚院花留立，春窗月伴眠。回眸虽欲语，阿母在傍边。<EOP></br></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s><START>秃人今日已定，不须卜於长安。天坐住汝男津，百官大会千斤肫。<EOP></br></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s><START>肃肃雍雍义有余，九天鸞凤莫相疎。唯应静向山窗过，激发英雄夜读书。<EOP></br></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s><START>管急弦繁拍渐稠，绿腰宛转曲终头。诚知乐世声声乐，老病人听未免愁。<EOP></br></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s><START>多雨殊未已，秋云更沈沈。洛阳故人初解印，山东小吏来相寻。上卿才大名不朽，早朝至尊暮求友。豁达常推海内贤，殷勤但酌尊中酒。饮醉欲言归剡溪，门前驷马光照衣。路傍观者徒唧唧，我公不以为是非。<EOP></br></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s><START>大君膺宝历，出豫表功成。钧天金石响，洞庭弦管清。八音动繁会，九变叶希声。和云留睿赏，熏风悅圣情。盛烈光韶濩，易俗迈咸英。窃吹良无取，率舞抃羣生。<EOP></br><START>之子逍遥尘世薄，格淡於云语如鹤。相见唯谈海上山，碧侧青斜冷相沓。芒鞋竹杖寒冻时，玉霄忽去非有期。僮担亦笼密雪里，世人无人留得之。想入红霞路深邃，孤峰纵啸仙飙起。星精聚观泣海鬼，月湧薄烟花点水。送君丁宁有深旨，好寻佛窟游银地。雪眉衲僧皆正气，伊昔贞白'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt = '</br>'.join([''.join(poetry) for poetry in poetrys])\n",
    "txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_poetries = []\n",
    "# 分别以这几个字作为诗歌的第一个字，生成8首诗\n",
    "for word in list(u'春'):\n",
    "    gen_poetry = ''.join(generate(model, word, ix2word, word2ix))\n",
    "    gen_poetries.append(gen_poetry)\n",
    "txt = '\\n'.join([''.join(poetry) for poetry in gen_poetries])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'春来不见人不知，人家女儿弄金屋。天涯相见不可论，万里千山万丈余。青荧数点奇奇士，白日葱茏生八区。东山桃李夹城东，西陵道路人不同。顾君余笑为谁子，忆昔陈家亦相望。一从遇此学为名，十年为客无遗名。君不见东西衮衮客，一年何处无人识。君今不见东方来，今日独有江州吟。君不见邺中有美酒，江上一行何处寻。使我哀心自此乐，一夜独向江南去。'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PoetryModel(\n",
       "  (embeddings): Embedding(8293, 128)\n",
       "  (lstm): LSTM(128, 256, num_layers=2)\n",
       "  (linear1): Linear(in_features=256, out_features=8293, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[8291]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = Variable(t.Tensor([word2ix['<START>']]).view(1, 1).long())\n",
    "input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "output, hidden = model(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_index = output.data[0].topk(1)[1][0]\n",
    "w = ix2word[top_index.item()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'</s>'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PoetryModel(len(word2ix), 128, 256);\n",
    "map_location = lambda s, l: s\n",
    "state_dict = t.load('D:/project/ml/data/tang_199.pth', map_location=map_location)\n",
    "model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "闲云潭影日悠悠，千里万里无人愁。人生不及春已暮，妾家独歌长安曲。西楼月，月明中，一夜东风吹晓雨。今年花落春风起，杨柳青青鸦在水。柳条繁，柳条垂，柳条丝管，杯酒满袖，歌语声尽画蛾眉。妆成蹋，望山云，复君心。妾心明月月如珠翠，绣户垂珰。陵上一行春半，月明双燕燕来。一曲弦歌，女笛歌回。愿言君王镇魏王女，传歌金马不成回。第一斗斛三五，三十六宫千万里。金龙雄劒佩金梭，玉关银汉照金绳。帐前珠佩芙蓉幕，蜡炬光辉\n"
     ]
    }
   ],
   "source": [
    "gen()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
